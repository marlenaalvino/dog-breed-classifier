{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3529cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import os\n",
    "import json\n",
    "import timm\n",
    "import torch\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from contextlib import nullcontext\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from timm.data import resolve_model_data_config\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b8288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seeds for reproducibility\n",
    "SEED = 27\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6b219c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the data paths\n",
    "ORIGINAL_DATA_PATH = \"data/raw/images\"\n",
    "SPLIT_DATA_PATH = \"data/processed\"\n",
    "\n",
    "# Initialize the split ratios and number of classes\n",
    "VALID_SIZE = 0.15\n",
    "TEST_SIZE = 0.15\n",
    "NUM_CLASSES = 120\n",
    "\n",
    "# Initialize the data pipeline hyperparameters\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8bc3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns True if the file at the specified path is an uncorrupted image, False otherwise\n",
    "def is_image(path):\n",
    "    try:\n",
    "        Image.open(path).verify()\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "# Performs a stratified split of the data into training, validation, and test sets\n",
    "def split_data(input_path, output_path, valid_size=VALID_SIZE, test_size=TEST_SIZE):\n",
    "    # Remove any existing data split directories\n",
    "    if os.path.exists(output_path):\n",
    "        shutil.rmtree(output_path)\n",
    "\n",
    "    # Create the train, valid, and test directories\n",
    "    for dir in [\"train\", \"valid\", \"test\"]:\n",
    "        os.makedirs(os.path.join(output_path, dir), exist_ok=True)\n",
    "\n",
    "    # Iterate through each dog breed directory\n",
    "    breed_dirs = [d for d in os.listdir(input_path) if os.path.isdir(os.path.join(input_path, d))]\n",
    "    for breed in breed_dirs:\n",
    "        # Get all the image names for the current breed\n",
    "        breed_path = os.path.join(input_path, breed)\n",
    "        images = [f for f in os.listdir(breed_path) if is_image(os.path.join(breed_path, f))]\n",
    "\n",
    "        # Split the images into (train + validation) and test sets\n",
    "        train_valid_imgs, test_imgs = train_test_split(images, test_size=test_size, random_state=27)\n",
    "\n",
    "        # Further split the (train + validation) image set into train and validation sets\n",
    "        train_imgs, valid_imgs = train_test_split(train_valid_imgs, test_size=valid_size/(1-test_size), random_state=27)\n",
    "\n",
    "        # Copy the images into their appropriate locations\n",
    "        for set, img_list in zip(['train', 'valid', 'test'], [train_imgs, valid_imgs, test_imgs]):\n",
    "            set_breed_path = os.path.join(output_path, set, breed)\n",
    "            os.makedirs(set_breed_path, exist_ok=True)\n",
    "            for img in img_list:\n",
    "                shutil.copy(os.path.join(breed_path, img), os.path.join(set_breed_path, img))\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "split_data(ORIGINAL_DATA_PATH, SPLIT_DATA_PATH, VALID_SIZE, TEST_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f39826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the EfficientNet-B3 model, pretrained on ImageNet-1K, and replace its head\n",
    "model = timm.create_model(\"efficientnet_b3\", pretrained=True, num_classes=NUM_CLASSES)\n",
    "\n",
    "# Retrieve the model configurations to ensure that inputs will adhere to them\n",
    "data_config = resolve_model_data_config(model)\n",
    "img_size = data_config[\"input_size\"][-1]\n",
    "mean = data_config[\"mean\"]\n",
    "std = data_config[\"std\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b52d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns datasets and data loaders, including transformations, for training, validation, and testing\n",
    "def get_dataloaders(data_dir, img_size=img_size, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS):\n",
    "    # Create data transformations for training and validation/testing\n",
    "    train_transforms = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(img_size, scale=(0.8, 1.0)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.ColorJitter(\n",
    "            brightness=0.1,\n",
    "            contrast=0.1,\n",
    "            saturation=0.1,\n",
    "            hue=0.02\n",
    "        ),\n",
    "        transforms.RandomRotation(degrees=10),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std),\n",
    "    ])\n",
    "\n",
    "    valid_test_transforms = transforms.Compose([\n",
    "        transforms.Resize(int(img_size * 1.15)),\n",
    "        transforms.CenterCrop(img_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std),\n",
    "    ])\n",
    "    image_transforms = {\n",
    "        \"train\":train_transforms,\n",
    "        \"valid_test\":valid_test_transforms\n",
    "    }\n",
    "\n",
    "    # Create datasets for training, validation, and testing\n",
    "    image_datasets = {\n",
    "        \"train\":datasets.ImageFolder(root=os.path.join(data_dir, \"train\"), transform=train_transforms),\n",
    "        \"valid\":datasets.ImageFolder(root=os.path.join(data_dir, \"valid\"), transform=valid_test_transforms),\n",
    "        \"test\":datasets.ImageFolder(root=os.path.join(data_dir, \"test\"), transform=valid_test_transforms)\n",
    "    }\n",
    "\n",
    "    # Create data loaders for training, validation, and testing\n",
    "    data_loaders = {\n",
    "        \"train\":DataLoader(image_datasets[\"train\"], batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True, generator=torch.Generator().manual_seed(SEED)),\n",
    "        \"valid\":DataLoader(image_datasets[\"valid\"], batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True),\n",
    "        \"test\":DataLoader(image_datasets[\"test\"], batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "    }\n",
    "\n",
    "    # Return the datasets and data loaders\n",
    "    return image_transforms, image_datasets, data_loaders\n",
    "\n",
    "# Initialize the datasets and data loaders\n",
    "image_transforms, image_datasets, data_loaders = get_dataloaders(SPLIT_DATA_PATH, img_size, BATCH_SIZE, NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931392e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine which device to use (GPU if available, else CPU)\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "# Determine whether to use automatic mixed precision (AMP) based on the device\n",
    "use_amp = device.type in {\"cuda\", \"mps\"}\n",
    "\n",
    "# Move the model to the selected device\n",
    "model.to(device)\n",
    "\n",
    "# Output the device being used\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0984bd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a list of the model's head parameters\n",
    "def get_head_params(model):\n",
    "    return list(model.get_classifier().parameters())\n",
    "\n",
    "# Returns a list of the model's backbone parameters\n",
    "def get_backbone_params(model):\n",
    "    head_ids = {id(p) for p in get_head_params(model)}\n",
    "    return [p for p in model.parameters() if id(p) not in head_ids]\n",
    "\n",
    "# Freezes all the model's parameters\n",
    "def freeze_all(model):\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "# Unfreezes only the model's head parameters\n",
    "def unfreeze_head_only(model):\n",
    "    freeze_all(model)\n",
    "    for p in get_head_params(model):\n",
    "        p.requires_grad = True\n",
    "\n",
    "# Unfreezes all the model's parameters\n",
    "def unfreeze_all(model):\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = True\n",
    "\n",
    "# Returns the appropriate autocast context manager based on the device and AMP usage\n",
    "def autocast_ctx(device=device, use_amp=use_amp):\n",
    "    if not use_amp:\n",
    "        return nullcontext()\n",
    "    if device.type == \"cuda\":\n",
    "        return torch.amp.autocast(\"cuda\", dtype=torch.float16)\n",
    "    if device.type == \"mps\":\n",
    "        return torch.amp.autocast(\"mps\", dtype=torch.float16)\n",
    "    return nullcontext()\n",
    "\n",
    "# Trains the model for one epoch\n",
    "def train_one_epoch(model, dataloader, device, use_amp, criterion, optimizer, scaler=None):\n",
    "    # Switch the model into training mode\n",
    "    model.train()\n",
    "\n",
    "    # Initialize running loss and accuracy metric variables\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Load the data in batches\n",
    "    for inputs, labels in dataloader:\n",
    "        # Move the images and labels to the selected device\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Reset the optimizer's gradients\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        # If using AMP, perform the forward and backward passes with mixed precision\n",
    "        if scaler is not None and use_amp:\n",
    "            with autocast_ctx(device, use_amp):\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "        # Otherwise, perform the forward and backward passes normally\n",
    "        else:\n",
    "            with autocast_ctx(device, use_amp):\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Update the running loss and accuracy metrics\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        preds = outputs.argmax(1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    # Return the average loss and accuracy for the epoch\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "# Evaluates the model on a validation or test dataset, returning the loss and accuracy\n",
    "def evaluate(model, dataloader, device, use_amp, criterion):\n",
    "    # Switch the model into evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Initialize running loss and accuracy metric variables\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Disable gradient computation for evaluation\n",
    "    with torch.no_grad():\n",
    "        # Load the data in batches\n",
    "        for inputs, labels in dataloader:\n",
    "            # Move the images and labels to the selected device\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # With the necessary autocast context, perform the forward pass\n",
    "            with autocast_ctx(device, use_amp):\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            # Update the running loss and accuracy metrics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = outputs.max(1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    # Return the average loss and accuracy for the current model and dataset\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "# Runs a training phase for a specified number of epochs, with optional early stopping\n",
    "def run_training_phase(phase_name, start_epoch, num_epochs, model, train_loader, val_loader, device, use_amp, criterion,\n",
    "                       optimizer, scheduler, scaler, best_val_acc, history, ckpt_path, early_stopping_patience=None):\n",
    "    # Initialize variables for tracking the current epoch and early stopping\n",
    "    epoch = start_epoch\n",
    "    no_improve = 0\n",
    "\n",
    "    # Train the model for the specified number of epochs\n",
    "    for i in range(num_epochs):\n",
    "        # Train the model for one epoch, recording the training loss and accuracy\n",
    "        train_loss, train_acc = train_one_epoch(model, train_loader, device, use_amp, criterion, optimizer, scaler)\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"train_accuracy\"].append(train_acc)\n",
    "\n",
    "        # Evaluate the model on the validation dataset, recording the validation loss and accuracy\n",
    "        val_loss, val_acc = evaluate(model, val_loader, device, use_amp, criterion)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"val_accuracy\"].append(val_acc)\n",
    "\n",
    "        # Update the learning rate scheduler, if one is provided\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        # If the current validation accuracy is the best so far, save the model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            ckpt_dir = os.path.dirname(ckpt_path)\n",
    "            if ckpt_dir:\n",
    "                os.makedirs(ckpt_dir, exist_ok=True)\n",
    "            torch.save(\n",
    "                {\n",
    "                    \"epoch\": epoch,\n",
    "                    \"model_state_dict\": model.state_dict(),\n",
    "                    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                    \"val_acc\": val_acc,\n",
    "                },\n",
    "                ckpt_path,\n",
    "            )\n",
    "            no_improve = 0\n",
    "\n",
    "        # Otherwise, increment the no improvement counter for early stopping, if applicable\n",
    "        else:\n",
    "            if early_stopping_patience is not None:\n",
    "                no_improve += 1\n",
    "                # If the early stopping threshold has been met, stop training\n",
    "                if no_improve >= early_stopping_patience:\n",
    "                    print(f\"[{phase_name}] Early stopping at epoch {epoch} after {no_improve} epochs without improvement.\")\n",
    "                    print(f\"\\tBest Validation Accuracy: {best_val_acc:.3f}\")\n",
    "                    print(f\"\\tCheckpoint saved to {ckpt_path}\")\n",
    "                    break\n",
    "\n",
    "        # Output the training and validation metrics for the current epoch\n",
    "        print(\n",
    "            f\"[{phase_name} {i+1}/{num_epochs} | Epoch {epoch}] \"\n",
    "            f\"train_loss={train_loss:.3f} train_acc={train_acc:.3f} \"\n",
    "            f\"val_loss={val_loss:.3f} val_acc={val_acc:.3f} \"\n",
    "            f\"(best_val_acc={best_val_acc:.3f})\"\n",
    "        )\n",
    "\n",
    "        # Increment the epoch counter\n",
    "        epoch += 1\n",
    "\n",
    "    # Return the best validation accuracy and the epoch at which training concluded\n",
    "    return best_val_acc, epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "__qB2FjoOxPt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training hyperparameters and model checkpoint path\n",
    "P1_EPOCHS = 10\n",
    "P2_EPOCHS = 15\n",
    "PATIENCE = 4\n",
    "BEST_MODEL_PATH = \"models/best_model.pth\"\n",
    "FINAL_MODEL_PATH = \"models/final_model.pth\"\n",
    "\n",
    "# Define the loss criterion and AMP scaler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scaler = None if not use_amp else torch.amp.GradScaler(device.type)\n",
    "\n",
    "# Initialize variables to track the best validation accuracy, current epoch, and training history\n",
    "best_val_acc = 0\n",
    "current_epoch = 0\n",
    "history = {\"train_loss\": [], \"train_accuracy\": [], \"val_loss\": [], \"val_accuracy\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0a39f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Phase 1: Train the model's head only ----\n",
    "# Unfreeze only the model's head\n",
    "unfreeze_head_only(model)\n",
    "\n",
    "# Create the optimizer and learning rate scheduler for phase 1\n",
    "optimizer_p1 = torch.optim.AdamW(get_head_params(model), lr=1e-3, weight_decay=1e-4)\n",
    "scheduler_p1 = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_p1, T_max=P1_EPOCHS)\n",
    "\n",
    "# Run the training phase for Phase 1: Warmup\n",
    "best_val_acc, current_epoch = run_training_phase(\"Warmup\", current_epoch, P1_EPOCHS, model, data_loaders[\"train\"], data_loaders[\"valid\"],\n",
    "                                                 device, use_amp, criterion, optimizer_p1, scheduler_p1, scaler, best_val_acc, history,\n",
    "                                                 BEST_MODEL_PATH, PATIENCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MBJ0QMRKO0lp",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Phase 2: Train the entire model ----\n",
    "# Unfreeze all the model's layers\n",
    "unfreeze_all(model)\n",
    "\n",
    "# Create the optimizer and learning rate scheduler for phase 2\n",
    "optimizer_p2 = torch.optim.AdamW(\n",
    "        [\n",
    "            {\"params\": get_backbone_params(model), \"lr\": 1e-4},\n",
    "            {\"params\": get_head_params(model), \"lr\": 5e-4},\n",
    "        ],\n",
    "        weight_decay=1e-4,\n",
    "    )\n",
    "scheduler_p2 = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_p2, T_max=P2_EPOCHS)\n",
    "\n",
    "# Run the training phase for Phase 2: Fine-tuning\n",
    "best_val_acc, current_epoch = run_training_phase(\"Fine-tuning\", current_epoch, P2_EPOCHS, model, data_loaders[\"train\"], data_loaders[\"valid\"],\n",
    "                                                 device, use_amp, criterion, optimizer_p2, scheduler_p2, scaler, best_val_acc, history,\n",
    "                                                 BEST_MODEL_PATH, PATIENCE)\n",
    "\n",
    "# Save the final model\n",
    "\n",
    "torch.save(model.state_dict(), FINAL_MODEL_PATH)\n",
    "print(f\"Final checkpoint saved to {FINAL_MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9142cdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots the training and validation curves for a given metric (Loss or Accuracy)\n",
    "def plot_training_metric(history, metric=\"Loss\"):\n",
    "    values_train = history[f\"train_{metric.lower()}\"]\n",
    "    values_val = history[f\"val_{metric.lower()}\"]\n",
    "    epochs = range(1, len(values_train) + 1)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(epochs, values_train, label=f\"Training {metric}\", linewidth=2, color=\"#C3985F\")\n",
    "    plt.plot(epochs, values_val, label=f\"Validation {metric}\", linewidth=2, color=\"#825218\")\n",
    "\n",
    "    plt.gca().xaxis.set_major_locator(plt.MaxNLocator(integer=True))\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.title(f\"Training and Validation {metric} vs. Epochs\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot the training and validation loss and accuracy curves\n",
    "plot_training_metric(history, \"Loss\")\n",
    "plot_training_metric(history, \"Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc2ad10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the predictions and probabilities for a batch of images\n",
    "def predict_batch(model, images, device, k=1):\n",
    "    # Switch the model into evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Disable gradient computation for evaluation\n",
    "    with torch.no_grad():\n",
    "        # Move the images to the selected device \n",
    "        images = images.to(device)\n",
    "\n",
    "        # Run the model and convert the logits to probabilities\n",
    "        outputs = model(images)\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "\n",
    "        # If requesting only the top-1 prediction...\n",
    "        if k == 1:\n",
    "            # Retrieve the highest-probability class and return the predictions and probabilities\n",
    "            preds = torch.argmax(probs, dim=1)\n",
    "            return preds.cpu(), probs.cpu()\n",
    "        \n",
    "        # Otherwise...\n",
    "        else:\n",
    "            # Retrieve and return the top-k predictions and their probabilities\n",
    "            top_probs, top_idxs = probs.topk(k, dim=1)\n",
    "            return top_idxs.cpu(), top_probs.cpu()\n",
    "\n",
    "# Returns the predictions, targets, and probabilities for an entire dataset\n",
    "def predict_dataset(model, dataloader, device, k=1, as_tensor=False):\n",
    "    # Initialize lists to store all the predictions, targets, and probabilities\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    all_probs = []\n",
    "\n",
    "    # Switch the model into evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Disable gradient computation for evaluation\n",
    "    with torch.no_grad():\n",
    "        # Load the data in batches\n",
    "        for images, labels in dataloader:\n",
    "            # Run batch prediction and record the results \n",
    "            preds, probs = predict_batch(model, images, device, k)\n",
    "            all_preds.append(preds)\n",
    "            all_probs.append(probs)\n",
    "            all_targets.append(labels.cpu())\n",
    "\n",
    "    # Concatenate all the batch outputs into full-dataset tensors, optionally convert them to lists, and return them\n",
    "    if as_tensor: \n",
    "        return (torch.cat(all_preds), torch.cat(all_targets), torch.cat(all_probs))\n",
    "    else:\n",
    "        return (torch.cat(all_preds).tolist(), torch.cat(all_targets).tolist(), torch.cat(all_probs).tolist())\n",
    "\n",
    "# Returns the prediction and probabilities for a single image\n",
    "def predict_single(model, img_path, transform, device, k=1):\n",
    "    # Switch the model into evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # If the file at the specified path is a valid image...\n",
    "    if is_image(img_path):\n",
    "        # Load and preprocess the image\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        tensor = transform(img).unsqueeze(0)        # Create a batch of size 1\n",
    "\n",
    "        # Run batch prediction\n",
    "        preds, probs = predict_batch(model, tensor, device, k)\n",
    "\n",
    "        # Extract and return the results for the single image\n",
    "        if k == 1:\n",
    "            return preds[0].item(), probs[0].tolist()\n",
    "        else:\n",
    "            return preds[0].tolist(), probs[0].tolist()\n",
    "\n",
    "# Computes the top-k accuracy of the model on a given dataset   \n",
    "def compute_accuracy_topk(model, dataloader, device, k=1):\n",
    "    # Get the predictions and targets for the entire dataset\n",
    "    preds, targets, _ = predict_dataset(model, dataloader, device, k=k, as_tensor=True)\n",
    "\n",
    "    # For top-1 accuracy, count exact matches between the predicted and true labels\n",
    "    if k == 1:\n",
    "        correct = (preds == targets).sum().item()\n",
    "        total = targets.size(0)\n",
    "        return correct / total\n",
    "    \n",
    "    # For top-k accuracy, count samples where the true label appears in the top-k predictions\n",
    "    else:\n",
    "        correct = 0\n",
    "        for i in range(len(targets)):\n",
    "            if targets[i].item() in preds[i]:\n",
    "                correct += 1\n",
    "        return correct / len(targets)\n",
    "    \n",
    "# Computes the accuracy per dog breed for corresponding predictions and targets\n",
    "def compute_accuracy_per_breed(preds, targets):\n",
    "    # Initialize a dictionary to store breed statistics (correct and total counts)\n",
    "    breed_stats = {}\n",
    "\n",
    "    # Iterate over all the predictions and targets\n",
    "    for true_breed, pred_breed in zip(targets, preds):\n",
    "        # Add the current breed to the dictionary if it's not already present\n",
    "        if true_breed not in breed_stats:\n",
    "            breed_stats[true_breed] = {\"correct\": 0, \"total\": 0}\n",
    "\n",
    "        # Update the correct and total counts for the current breed\n",
    "        if pred_breed == true_breed:\n",
    "            breed_stats[true_breed][\"correct\"] += 1\n",
    "        breed_stats[true_breed][\"total\"] += 1\n",
    "\n",
    "    # Convert the counts to accuracy for each breed\n",
    "    breed_accuracy = {\n",
    "        breed: stats[\"correct\"] / stats[\"total\"]\n",
    "        for breed, stats in breed_stats.items()\n",
    "    }\n",
    "\n",
    "    # Return the accuracy-per-breed dictionary\n",
    "    return breed_accuracy\n",
    "\n",
    "# Plots a confusion matrix for the given predictions and targets\n",
    "def plot_confusion_matrix(preds, targets, class_names, normalize=False, figsize=(12, 10)):\n",
    "    # Compute the confusion matrix\n",
    "    cm = confusion_matrix(targets, preds, labels=class_names, normalize='true' if normalize else None)\n",
    "    \n",
    "    # Plot the heatmap\n",
    "    plt.figure(figsize=figsize)\n",
    "    ax = sns.heatmap(\n",
    "        cm,\n",
    "        annot=False,\n",
    "        cmap=\"Blues\",\n",
    "        xticklabels= False,\n",
    "        yticklabels=False\n",
    "    )\n",
    "    ax.set_xticks(range(len(class_names)))\n",
    "    ax.set_yticks(range(len(class_names)))\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.title(\"Confusion Matrix\" + (\" (Normalized)\" if normalize else \"\"))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plots a confusion matrix for the k most confused classes (lowest per-class accuracy)\n",
    "def plot_topk_confusion_matrix(preds, targets, acc_per_breed=None, k=10, normalize=False, figsize=(10, 8)):\n",
    "    # Compute the accuracy per breed as necessary\n",
    "    if acc_per_breed is None:\n",
    "        acc_per_breed = compute_accuracy_per_breed(preds, targets)\n",
    "\n",
    "    # Sort the breeds by accuracy (ascending) and select the k worst-performing breeds\n",
    "    sorted_breeds = sorted(acc_per_breed.items(), key=lambda x: x[1])\n",
    "    worst_breeds = [breed for breed, _ in sorted_breeds[:k]]\n",
    "\n",
    "    # Compute the confusion matrix restricted to these breeds\n",
    "    cm = confusion_matrix(targets, preds, labels=worst_breeds, normalize='true' if normalize else None)\n",
    "\n",
    "    # Plot the heatmap\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.heatmap(cm, annot=False, cmap=\"Blues\", xticklabels=worst_breeds, yticklabels=worst_breeds)\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.title(\n",
    "        f\"Confusion Matrix for the {k} Lowest-Accuracy Breeds\"\n",
    "        + (\" (Normalized)\" if normalize else \"\")\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Returns a list of class names from the class mapping JSON file\n",
    "def get_class_names(class_mapping_path=\"class_mapping.json\"):\n",
    "    with open(class_mapping_path, \"r\") as f:\n",
    "        class_mapping = json.load(f)\n",
    "    return [class_mapping[key] for key in sorted(class_mapping.keys())]\n",
    "\n",
    "# Converts a class index (or a list of class indexes) to human-readable dog breed names\n",
    "def class_idx_to_breed(class_idx, class_mapping_path=\"class_mapping.json\"):\n",
    "    # Load the class mapping from the JSON file\n",
    "    with open(class_mapping_path, \"r\") as f:\n",
    "        class_mapping = json.load(f)\n",
    "\n",
    "    # If a single index is provided, convert it to a list for uniform processing\n",
    "    single_input = False\n",
    "    if isinstance(class_idx, int):\n",
    "        class_idx = [class_idx]\n",
    "        single_input = True\n",
    "\n",
    "    # Map each class index to its corresponding dog breed name\n",
    "    keys = sorted(class_mapping.keys())\n",
    "    breed_names = [class_mapping[keys[idx]] for idx in class_idx]\n",
    "\n",
    "    # If the input was a single index, return a single breed name\n",
    "    if single_input:\n",
    "        return breed_names[0]\n",
    "    \n",
    "    # Otherwise, return a list of breed names\n",
    "    return breed_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f92cf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model\n",
    "checkpoint = torch.load(BEST_MODEL_PATH, map_location=device)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf94a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the validation dataset and report its loss and accuracy\n",
    "val_loss, val_acc = evaluate(model, data_loaders[\"valid\"], device, use_amp, criterion)\n",
    "print(f\"Final Validation Loss: {val_loss:.4f}, Final Validation Accuracy: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c4e53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test dataset and report its loss and accuracy\n",
    "test_loss, test_acc = evaluate(model, data_loaders[\"test\"], device, use_amp, criterion)\n",
    "print(f\"Final Test Loss: {test_loss:.4f}, Final Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9b3be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and report the top-5 accuracy on the test dataset\n",
    "top5_test_acc = compute_accuracy_topk(model, data_loaders[\"test\"], device, k=5)\n",
    "print(f\"Final Test Top-5 Accuracy: {top5_test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b9411e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the predictions and targets for the test dataset\n",
    "preds, targets, _ = predict_dataset(model, data_loaders[\"test\"], device)\n",
    "preds, targets = class_idx_to_breed(preds), class_idx_to_breed(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cecc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and report the accuracy per dog breed\n",
    "accuracy_per_breed = compute_accuracy_per_breed(preds, targets)\n",
    "print(\"Accuracy per Breed: \\n\", accuracy_per_breed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5d097f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the full and top-10 confusion matrices\n",
    "class_names = get_class_names()\n",
    "plot_confusion_matrix(preds, targets, class_names, normalize=True)\n",
    "plot_topk_confusion_matrix(preds, targets, accuracy_per_breed, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7565d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of image paths from the additional_images directory\n",
    "directory = \"additional_images\"\n",
    "exts = {\".jpg\", \".jpeg\", \".png\"}\n",
    "image_paths = [\n",
    "    os.path.join(directory, f)\n",
    "    for f in os.listdir(directory)\n",
    "    if os.path.splitext(f.lower())[1] in exts\n",
    "]\n",
    "\n",
    "# Output a prediction for each image in the directory\n",
    "for img_path in image_paths:\n",
    "    # Extract the image name for display\n",
    "    base = os.path.basename(img_path)\n",
    "    name = os.path.splitext(base)[0].capitalize()\n",
    "\n",
    "    # Predict the dog breed for the current image\n",
    "    pred_idx, _ = predict_single(model, img_path, image_transforms[\"valid_test\"], device, k=1)\n",
    "    pred_breed = class_idx_to_breed(pred_idx)\n",
    "\n",
    "    # Output the prediction results\n",
    "    print(f\"{name}: {pred_breed}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
