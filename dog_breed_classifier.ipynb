{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bbf016b",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- Double check class_mapping.json\n",
    "- Create necessary hyperparameter constants\n",
    "- Add references to README"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3529cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marlenaalvino/Desktop/ML/ML/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import timm\n",
    "import torch\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from timm.data import resolve_model_data_config\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc6b219c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants and hyperparameters\n",
    "ORIGINAL_DATA_PATH = \"Data/Raw/Images\"\n",
    "SPLIT_DATA_PATH = \"Data/Processed\"\n",
    "\n",
    "VALID_SIZE = 0.15\n",
    "TEST_SIZE = 0.15\n",
    "\n",
    "NUM_CLASSES = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8bc3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns True if the file at the specified path is an uncorrupted image; False otherwise\n",
    "def is_image(path):\n",
    "    try:\n",
    "        Image.open(path).verify()\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "# Performs a stratified split of the data into training, validation, and test sets\n",
    "def split_data(input_path, output_path, valid_size=VALID_SIZE, test_size=TEST_SIZE):\n",
    "    # Clean up any existing data splits\n",
    "    for dir in [output_path, \"Train\", \"Valid\", \"Test\"]:\n",
    "        if os.path.exists(dir):\n",
    "            shutil.rmtree(dir)\n",
    "\n",
    "    # Create the Train, Valid, and Test directories\n",
    "    for dir in [\"Train\", \"Valid\", \"Test\"]:\n",
    "        os.makedirs(os.path.join(output_path, dir), exist_ok=True)\n",
    "\n",
    "    # \n",
    "    breed_dirs = [d for d in os.listdir(input_path) if os.path.isdir(os.path.join(input_path, d))] \n",
    "    for breed in breed_dirs:\n",
    "        # Get all image names for the current breed\n",
    "        breed_path = os.path.join(input_path, breed)\n",
    "        images = [f for f in os.listdir(breed_path) if is_image(os.path.join(breed_path, f))]\n",
    "\n",
    "        # Split the images into (train + validation) and test sets\n",
    "        train_valid_imgs, test_imgs = train_test_split(images, test_size=test_size, random_state=27) \n",
    "\n",
    "        # Further split the (train + validation) image set into train and validation sets\n",
    "        train_imgs, valid_imgs = train_test_split(train_valid_imgs, test_size=valid_size/(1-test_size), random_state=27)\n",
    "\n",
    "        # Copy images into their appropriate locations\n",
    "        for set, img_list in zip(['Train', 'Valid', 'Test'], [train_imgs, valid_imgs, test_imgs]):\n",
    "            set_breed_path = os.path.join(output_path, set, breed)\n",
    "            os.makedirs(set_breed_path, exist_ok=True)\n",
    "            for img in img_list:\n",
    "                shutil.copy(os.path.join(breed_path, img), os.path.join(set_breed_path, img))\n",
    "\n",
    "split_data(ORIGINAL_DATA_PATH, SPLIT_DATA_PATH, VALID_SIZE, TEST_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d23af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the EfficientNet-B3 model, pretrained on ImageNet-1K, and replace its head \n",
    "model = timm.create_model(\n",
    "    \"efficientnet_b3\",\n",
    "    pretrained=True,\n",
    "    num_classes=NUM_CLASSES\n",
    ")\n",
    "\n",
    "# Retrieve model configurations to ensure that future inputs adhere to them \n",
    "data_config = resolve_model_data_config(model)\n",
    "img_size = data_config[\"input_size\"][-1]\n",
    "mean = data_config[\"mean\"]\n",
    "std = data_config[\"std\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b52d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO declare BATCH_SIZE and NUM_WORKERS\n",
    "def get_dataloaders(data_dir, img_size=img_size, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS):\n",
    "    # TODO add augmentations to train_transforms \n",
    "    # Transforms\n",
    "    train_transforms = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(img_size, scale=(0.8, 1.0)), \n",
    "        transforms.\n",
    "        # Augment (flip, rotation, color jitter)\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std),\n",
    "    ])\n",
    "\n",
    "    #     transforms.RandomHorizontalFlip(p=0.5),\n",
    "    #     transforms.ColorJitter(\n",
    "    #         brightness=0.1,\n",
    "    #         contrast=0.1,\n",
    "    #         saturation=0.1,\n",
    "    #         hue=0.02\n",
    "    #     )\n",
    "\n",
    "    valid_test_transforms = transforms.Compose([\n",
    "        transforms.Resize(int(img_size * 1.15)),\n",
    "        transforms.CenterCrop(img_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std),\n",
    "    ])\n",
    "\n",
    "    # Datasets \n",
    "    train_dataset = datasets.ImageFolder(\n",
    "        root=os.path.join(data_dir, \"Train\"),\n",
    "        transform=train_transforms\n",
    "    )\n",
    "\n",
    "    valid_dataset = datasets.ImageFolder(\n",
    "        root=os.path.join(data_dir, \"Valid\"),\n",
    "        transform=valid_test_transforms\n",
    "    )\n",
    "\n",
    "    test_dataset = datasets.ImageFolder(\n",
    "        root=os.path.join(data_dir, \"Test\"),\n",
    "        transform=valid_test_transforms\n",
    "    )\n",
    "    image_datasets = {\"train\":train_dataset, \"valid\":valid_dataset, \"test\":test_dataset}\n",
    "\n",
    "    # TODO declare/update NUM_WORKERS according to machine specifications\n",
    "    # DataLoaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    data_loaders = {\"train\":train_loader, \"valid\":valid_loader, \"test\":test_loader}\n",
    "\n",
    "    return image_datasets, data_loaders\n",
    "\n",
    "# TODO update this call with appropriate inputs\n",
    "image_datasets, data_loaders = get_dataloaders(SPLIT_DATA_PATH, 30, img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44603abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two phase train; first on full images and then on cropped ones\n",
    "\n",
    "# Freeze all layers at first and then perform gradual unfreezing \n",
    "\n",
    "\n",
    "# Move the model, labels, and inputs to the device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model.to(device); # Semicolon to suppress output "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
