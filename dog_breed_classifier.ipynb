{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bbf016b",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- Double check class_mapping.json\n",
    "- Create necessary hyperparameter constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3529cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import timm\n",
    "import torch\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6b219c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants and hyperparameters\n",
    "RAW_DATA_PATH = \"Data/Raw/Images\"\n",
    "PROCESSED_DATA_PATH = \"Data/Processed\"\n",
    "\n",
    "VALID_SIZE = 0.15\n",
    "TEST_SIZE = 0.15\n",
    "\n",
    "NUM_CLASSES = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8bc3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns True if the file as the specified path is an uncorrupted image; False otherwise\n",
    "def is_image(path):\n",
    "    try:\n",
    "        Image.open(path).verify()\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "# Performs a stratified split of the data into training, validation, and test sets\n",
    "def split_data(input_path, output_path, valid_size, test_size):\n",
    "    # Clean up any existing data splits\n",
    "    for dir in [output_path, \"Train\", \"Valid\", \"Test\"]:\n",
    "        if os.path.exists(dir):\n",
    "            shutil.rmtree(dir)\n",
    "\n",
    "    # Create the Train, Valid, and Test directories\n",
    "    for dir in [\"Train\", \"Valid\", \"Test\"]:\n",
    "        os.makedirs(os.path.join(output_path, dir), exist_ok=True)\n",
    "\n",
    "    # \n",
    "    breed_dirs = [d for d in os.listdir(input_path) if os.path.isdir(os.path.join(input_path, d))] \n",
    "    for breed in breed_dirs:\n",
    "        # Get all image names for the current breed\n",
    "        breed_path = os.path.join(input_path, breed)\n",
    "        images = [f for f in os.listdir(breed_path) if is_image(os.path.join(breed_path, f))]\n",
    "\n",
    "        # Split the images into (train + validation) and test sets\n",
    "        train_valid_imgs, test_imgs = train_test_split(images, test_size=test_size, random_state=27) \n",
    "\n",
    "        # Further split the (train + validation) image set into train and validation sets\n",
    "        train_imgs, valid_imgs = train_test_split(train_valid_imgs, test_size=valid_size/(1-test_size), random_state=27)\n",
    "\n",
    "        # Copy images into their appropriate locations\n",
    "        for set, img_list in zip(['Train', 'Valid', 'Test'], [train_imgs, valid_imgs, test_imgs]):\n",
    "            set_breed_path = os.path.join(output_path, set, breed)\n",
    "            os.makedirs(set_breed_path, exist_ok=True)\n",
    "            for img in img_list:\n",
    "                shutil.copy(os.path.join(breed_path, img), os.path.join(set_breed_path, img))\n",
    "\n",
    "split_data(RAW_DATA_PATH, PROCESSED_DATA_PATH, VALID_SIZE, TEST_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b52d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create transforms to be applied dynamically\n",
    "    # Resize (TODO: look up ideal input to model)\n",
    "    # Normalize pixel values (TODO: look up ideal range and/or mean and std)\n",
    "    # For training, include data augmentationsâ€“including flips, to increase generalizability\n",
    "\n",
    "# Create data set definitions\n",
    "\n",
    "# Create data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edae11dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "base_model = timm.create_model(\n",
    "    \"efficientnet_b3\",\n",
    "    pretrained=True,\n",
    "    num_classes=NUM_CLASSES\n",
    ")\n",
    "\n",
    "# Freeze the layers \n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "base_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44603abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two phase train; first on full images and then on cropped ones"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
