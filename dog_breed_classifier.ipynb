{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bbf016b",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- Double check class_mapping.json\n",
    "- Create necessary hyperparameter constants\n",
    "- Add references to README"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3529cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import timm\n",
    "import torch\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from timm.data import resolve_model_data_config\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc6b219c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data paths\n",
    "ORIGINAL_DATA_PATH = \"Data/Raw/Images\"\n",
    "SPLIT_DATA_PATH = \"Data/Processed\"\n",
    "\n",
    "# \n",
    "VALID_SIZE = 0.15\n",
    "TEST_SIZE = 0.15\n",
    "NUM_CLASSES = 120\n",
    "\n",
    "# Model hyperparameters\n",
    "BATCH_SIZE = 8          # Max 12 \n",
    "EPOCHS = 20             # 3-5 to train head, 10-15 to train head + two top layers of base model\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_WORKERS = 2         # Max 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8bc3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns True if the file at the specified path is an uncorrupted image; False otherwise\n",
    "def is_image(path):\n",
    "    try:\n",
    "        Image.open(path).verify()\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "# Performs a stratified split of the data into training, validation, and test sets\n",
    "def split_data(input_path, output_path, valid_size=VALID_SIZE, test_size=TEST_SIZE):\n",
    "    # Clean up any existing data splits\n",
    "    for dir in [output_path, \"Train\", \"Valid\", \"Test\"]:\n",
    "        if os.path.exists(dir):\n",
    "            shutil.rmtree(dir)\n",
    "\n",
    "    # Create the Train, Valid, and Test directories\n",
    "    for dir in [\"Train\", \"Valid\", \"Test\"]:\n",
    "        os.makedirs(os.path.join(output_path, dir), exist_ok=True)\n",
    "\n",
    "    # \n",
    "    breed_dirs = [d for d in os.listdir(input_path) if os.path.isdir(os.path.join(input_path, d))] \n",
    "    for breed in breed_dirs:\n",
    "        # Get all image names for the current breed\n",
    "        breed_path = os.path.join(input_path, breed)\n",
    "        images = [f for f in os.listdir(breed_path) if is_image(os.path.join(breed_path, f))]\n",
    "\n",
    "        # Split the images into (train + validation) and test sets\n",
    "        train_valid_imgs, test_imgs = train_test_split(images, test_size=test_size, random_state=27) \n",
    "\n",
    "        # Further split the (train + validation) image set into train and validation sets\n",
    "        train_imgs, valid_imgs = train_test_split(train_valid_imgs, test_size=valid_size/(1-test_size), random_state=27)\n",
    "\n",
    "        # Copy images into their appropriate locations\n",
    "        for set, img_list in zip(['Train', 'Valid', 'Test'], [train_imgs, valid_imgs, test_imgs]):\n",
    "            set_breed_path = os.path.join(output_path, set, breed)\n",
    "            os.makedirs(set_breed_path, exist_ok=True)\n",
    "            for img in img_list:\n",
    "                shutil.copy(os.path.join(breed_path, img), os.path.join(set_breed_path, img))\n",
    "\n",
    "split_data(ORIGINAL_DATA_PATH, SPLIT_DATA_PATH, VALID_SIZE, TEST_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d23af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the EfficientNet-B3 model, pretrained on ImageNet-1K, and replace its head \n",
    "model = timm.create_model(\n",
    "    \"efficientnet_b3\",\n",
    "    pretrained=True,\n",
    "    num_classes=NUM_CLASSES\n",
    ")\n",
    "\n",
    "# Retrieve model configurations to ensure that inputs will adhere to them \n",
    "data_config = resolve_model_data_config(model)\n",
    "img_size = data_config[\"input_size\"][-1]\n",
    "mean = data_config[\"mean\"]\n",
    "std = data_config[\"std\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b52d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders(data_dir, img_size=img_size, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS):\n",
    "    # Transforms\n",
    "    train_transforms = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(img_size, scale=(0.8, 1.0)), \n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.ColorJitter(\n",
    "            brightness=0.1,\n",
    "            contrast=0.1,\n",
    "            saturation=0.1,\n",
    "            hue=0.02\n",
    "        ), \n",
    "\n",
    "        transforms.RandomRotation(degrees=10), \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std),\n",
    "    ])  \n",
    "\n",
    "    valid_test_transforms = transforms.Compose([\n",
    "        transforms.Resize(int(img_size * 1.15)),\n",
    "        transforms.CenterCrop(img_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std),\n",
    "    ])\n",
    "\n",
    "    # Image datasets \n",
    "    image_datasets = {\n",
    "        \"train\":datasets.ImageFolder(root=os.path.join(data_dir, \"Train\"), transform=train_transforms), \n",
    "        \"valid\":datasets.ImageFolder(root=os.path.join(data_dir, \"Valid\"), transform=valid_test_transforms), \n",
    "        \"test\":datasets.ImageFolder(root=os.path.join(data_dir, \"Test\"), transform=valid_test_transforms)\n",
    "    }\n",
    "\n",
    "    # DataLoaders\n",
    "    data_loaders = {\n",
    "        \"train\":DataLoader(image_datasets[\"train\"], batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True), \n",
    "        \"valid\":DataLoader(image_datasets[\"valid\"], batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True), \n",
    "        \"test\":DataLoader(image_datasets[\"test\"], batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "    }\n",
    "\n",
    "    return image_datasets, data_loaders\n",
    "\n",
    "image_datasets, data_loaders = get_dataloaders(SPLIT_DATA_PATH, img_size, BATCH_SIZE, NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29e2612",
   "metadata": {},
   "source": [
    "Phase 1 — Warmup (frozen backbone)\n",
    "\n",
    "- Freeze everything except the head.\n",
    "\n",
    "- Train 3–5 epochs with:\n",
    "\n",
    "    - lr = 1e-3\n",
    "\n",
    "    - batch_size = 8\n",
    "\n",
    "    - mixed precision on MPS\n",
    "\n",
    "Phase 2 — Minimal unfreeze\n",
    "\n",
    "- Unfreeze only the last block or last 2 blocks of EfficientNet-B3 + keep the head trainable.\n",
    "\n",
    "- Use lower LR for those unfrozen backbone layers, e.g.:\n",
    "    ```python\n",
    "    optimizer = AdamW(\n",
    "        [\n",
    "            {\"params\": backbone_last_blocks, \"lr\": 1e-4},\n",
    "            {\"params\": head_params, \"lr\": 5e-4},\n",
    "        ],\n",
    "        weight_decay=1e-4,\n",
    "    )\n",
    "    ```\n",
    "\n",
    "- Train 10–15 more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44603abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WOOF now i have to actually train this thing. \n",
    "\n",
    "# Freeze all layers at first and then perform gradual unfreezing \n",
    "\n",
    "\n",
    "# Move the model, labels, and inputs to the device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model.to(device); # Semicolon to suppress output "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
